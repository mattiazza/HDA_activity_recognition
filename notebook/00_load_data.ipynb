{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Data Analytics\n",
    "### Project D1: Activity Recognition\n",
    "\n",
    "Our goal is to obtain human activity recognition (HAR) through the use of Wi-Fi signal.\n",
    "\n",
    "\n",
    "## Imported Stuff\n",
    "\n",
    "Let's begin by importing the modules we'll use in this project:\n",
    " \n",
    "- <span style = \"color:cyan\">os</span>: allows us to interact with the operating system\n",
    "- <span style = \"color:cyan\">pathlib.Path</span>: allows us to work with file system paths in a easier way\n",
    "- <span style = \"color:cyan\">typing.NamedTuple</span>: to use tuple object with named fields (easier to manupulate)\n",
    "- <span style = \"color:cyan\">rich.print</span>: this module changes the look of how we print, making it more confortable to visualize and understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import NamedTuple\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported the necessary modules we want to gather the data needed to create the dataset we will use in this project.\n",
    "To do so we need to change our working directory (*HDA_activity_recognition/notebook* -> *HDA_activity_recognition/data*), that's where `os.chdir(\"..\")` and `os.getcwd()` came to hand  \n",
    "\n",
    "With `os.chdir(\"..\")` we change the current directory going up to the father directory.  \n",
    "`os.getcwd()` gets the current working directory.  \n",
    "\n",
    "\n",
    "**WARNING:** Running the next cell more than one time will change that many time the working directory!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To navigate through the *data* folder and collect all the data needed, let's create the class `MatFile` subclass of `NamedTuple` so we can have an easy access to:  \n",
    "\n",
    "- `dir_name`: string of the name of the directory containing the data \n",
    "- `dir_path`: full path of the directory\n",
    "- `f_name`: name of the file we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatFile(NamedTuple):\n",
    "    dir_name: str\n",
    "    dir_path: Path\n",
    "    f_name: str\n",
    "\n",
    "\n",
    "data_path = Path(\"data\")  # finds the path to the \"data\" directory\n",
    "data_list = data_path.glob(\n",
    "    \"*/*.mat\"\n",
    ")  # returns a list of every .mat file within the \"data\" directory and its subdirectory [.global(*/*.mat)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the list containing all the `.mat` files (`data_list`) we create the `mat_files` list and fill it with a `MatFile` for every file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MatFile</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">dir_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'AR-4a'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">dir_path</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Analytics/HDA_activity_recognition/data/AR-4a'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">f_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'AR4a_J2'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mMatFile\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mdir_name\u001b[0m=\u001b[32m'AR-4a'\u001b[0m,\n",
       "    \u001b[33mdir_path\u001b[0m=\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data \u001b[0m\n",
       "\u001b[32mAnalytics/HDA_activity_recognition/data/AR-4a'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mf_name\u001b[0m=\u001b[32m'AR4a_J2'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-3a'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-9b'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-8b'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-1d'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-8a'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-3b'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-1e'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-6a'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-1c'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-1a'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-4a'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-1b'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-9c'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-5a'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-5b'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-9a'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-2a'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-7a'</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-3a'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-9b'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-8b'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-1d'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-8a'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-3b'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-1e'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-6a'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-1c'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-1a'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-4a'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-1b'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-9c'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-5a'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-5b'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-9a'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-2a'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/AR-7a'\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat_files = []\n",
    "\n",
    "for data in data_list:  # data_list is a list with all Path object\n",
    "    mat_files.append(\n",
    "        MatFile(\n",
    "            dir_name=data.parent.name,  # with \".parent\" we recive the parent of data. With \".name\" we get its name\n",
    "            dir_path=data.parent.absolute(),  # \".absolute()\" returns all the complete path of the parent of data\n",
    "            f_name=data.name[:-4],\n",
    "        )\n",
    "    )\n",
    "\n",
    "mat_parents = set(\n",
    "    file.dir_path for file in mat_files\n",
    ")  # \"set()\" allows to keep just unique values\n",
    "\n",
    "print(mat_files[0])\n",
    "print(mat_parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_from_utils = \"cd activity_recognition/utils && poetry run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR3a_C2.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR9b_L3.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR8b_L1.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR1d_S.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR8a_E2.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR3b_E.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR1e_E.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR6a_L1.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR1c_C.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR1a_W.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR4a_J2.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR1b_W.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR9c_E.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR5a_J1.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR5b_R.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR9a_E.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR2a_L.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/CSI_phase_sanitization_signal_preprocessing.py\", line 98, in <module>\n",
      "    with open(name_file, \"wb\") as fp:  # Pickling\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './phase_processing/signal_AR7a_C.txt'\n"
     ]
    }
   ],
   "source": [
    "# Execute preprocessing from activity_recognitino/utils\n",
    "for directory in mat_parents:\n",
    "    os.system(\n",
    "        f\"{run_from_utils} python CSI_phase_sanitization_signal_preprocessing.py '{directory}/' 1 - 1 7 0\"\n",
    "    )\n",
    "\n",
    "# e.g. python CSI_phase_sanitization_signal_preprocessing.py ../input_files/S1a/ 1 - 1 4 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g., python CSI_phase_sanitization_H_estimation.py ../input_files/S1a/ 0 S1a_E 1 4 0 -1\n",
    "file_to_process = mat_files[0]\n",
    "os.system(\n",
    "    f\"{run_from_utils} python CSI_phase_sanitization_H_estimation.py '{file_to_process.dir_path}/' 0 {file_to_process.f_name} 1 7 0 -1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/.venv/bin/python: can't open file '/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data/CSI_phase_sanitization_signal_reconstruction.py': [Errno 2] No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\n",
    "    f\"{run_from_utils} python CSI_phase_sanitization_signal_reconstruction.py ./phase_processing/ ./processed_phase/ 1 7 0 -1 \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We Loaded the Dataset ;\\)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/data')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_from_data = Path(\"data\").absolute()\n",
    "run_from_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1a_E_stream_0\n",
      "S1a_E_stream_1\n",
      "S1a_E_stream_2\n",
      "S1a_E_stream_3\n",
      "S1a_J1_stream_0\n",
      "S1a_J1_stream_1\n",
      "S1a_J1_stream_2\n",
      "S1a_J1_stream_3\n",
      "S1a_J2_stream_0\n",
      "S1a_J2_stream_1\n",
      "S1a_J2_stream_2\n",
      "S1a_J2_stream_3\n",
      "S1a_L_stream_0\n",
      "S1a_L_stream_1\n",
      "S1a_L_stream_2\n",
      "S1a_L_stream_3\n",
      "S1a_R_stream_0\n",
      "S1a_R_stream_1\n",
      "S1a_R_stream_2\n",
      "S1a_R_stream_3\n",
      "S1a_W_stream_0\n",
      "S1a_W_stream_1\n",
      "S1a_W_stream_2\n",
      "S1a_W_stream_3\n",
      "S1b_E_stream_0\n",
      "S1b_E_stream_1\n",
      "S1b_E_stream_2\n",
      "S1b_E_stream_3\n",
      "S1b_J1_stream_0\n",
      "S1b_J1_stream_1\n",
      "S1b_J1_stream_2\n",
      "S1b_J1_stream_3\n",
      "S1b_J2_stream_0\n",
      "S1b_J2_stream_1\n",
      "S1b_J2_stream_2\n",
      "S1b_J2_stream_3\n",
      "S1b_L_stream_0\n",
      "S1b_L_stream_1\n",
      "S1b_L_stream_2\n",
      "S1b_L_stream_3\n",
      "S1b_R_stream_0\n",
      "S1b_R_stream_1\n",
      "S1b_R_stream_2\n",
      "S1b_R_stream_3\n",
      "S1b_W_stream_0\n",
      "S1b_W_stream_1\n",
      "S1b_W_stream_2\n",
      "S1b_W_stream_3\n",
      "ERROR - shapes mismatch\n",
      "ERROR - shapes mismatch\n",
      "ERROR - shapes mismatch\n",
      "S1c_E_stream_0\n",
      "S1c_E_stream_1\n",
      "S1c_E_stream_2\n",
      "S1c_E_stream_3\n",
      "S1c_J1_stream_0\n",
      "S1c_J1_stream_1\n",
      "S1c_J1_stream_2\n",
      "S1c_J1_stream_3\n",
      "S1c_J2_stream_0\n",
      "S1c_J2_stream_1\n",
      "S1c_J2_stream_2\n",
      "S1c_J2_stream_3\n",
      "S1c_L_stream_0\n",
      "S1c_L_stream_1\n",
      "S1c_L_stream_2\n",
      "S1c_L_stream_3\n",
      "S1c_R_stream_0\n",
      "S1c_R_stream_1\n",
      "S1c_R_stream_2\n",
      "S1c_R_stream_3\n",
      "S1c_W_stream_0\n",
      "S1c_W_stream_1\n",
      "S1c_W_stream_2\n",
      "S1c_W_stream_3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\n",
    "    f\"{run_from_utils} python CSI_doppler_create_dataset_train.py '{run_from_data}/doppler_traces/' S1a,S1b,S1c 31 1 340 30 E,L,W,R,J 4\"\n",
    ")\n",
    "\n",
    "# e.g., python CSI_doppler_create_dataset_train.py ./doppler_traces/ S1a,S1b,S1c 31 1 340 30 E,L,W,R,J 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2a_E_stream_0\n",
      "S2a_E_stream_1\n",
      "S2a_E_stream_2\n",
      "S2a_E_stream_3\n",
      "S2a_J_stream_0\n",
      "S2a_J_stream_1\n",
      "S2a_J_stream_2\n",
      "S2a_J_stream_3\n",
      "S2a_L_stream_0\n",
      "S2a_L_stream_1\n",
      "S2a_L_stream_2\n",
      "S2a_L_stream_3\n",
      "S2a_R_stream_0\n",
      "S2a_R_stream_1\n",
      "S2a_R_stream_2\n",
      "S2a_R_stream_3\n",
      "S2a_W_stream_0\n",
      "S2a_W_stream_1\n",
      "S2a_W_stream_2\n",
      "S2a_W_stream_3\n",
      "S2b_E_stream_0\n",
      "S2b_E_stream_1\n",
      "S2b_E_stream_2\n",
      "S2b_E_stream_3\n",
      "S2b_J1_stream_0\n",
      "S2b_J1_stream_1\n",
      "S2b_J1_stream_2\n",
      "S2b_J1_stream_3\n",
      "S2b_J2_stream_0\n",
      "S2b_J2_stream_1\n",
      "S2b_J2_stream_2\n",
      "S2b_J2_stream_3\n",
      "S2b_L_stream_0\n",
      "S2b_L_stream_1\n",
      "S2b_L_stream_2\n",
      "S2b_L_stream_3\n",
      "S2b_R_stream_0\n",
      "S2b_R_stream_1\n",
      "S2b_R_stream_2\n",
      "S2b_R_stream_3\n",
      "S2b_W_stream_0\n",
      "S2b_W_stream_1\n",
      "S2b_W_stream_2\n",
      "S2b_W_stream_3\n",
      "S3a_E_stream_0\n",
      "S3a_E_stream_1\n",
      "S3a_E_stream_2\n",
      "S3a_E_stream_3\n",
      "S3a_J1_stream_0\n",
      "S3a_J1_stream_1\n",
      "S3a_J1_stream_2\n",
      "S3a_J1_stream_3\n",
      "S3a_J2_stream_0\n",
      "S3a_J2_stream_1\n",
      "S3a_J2_stream_2\n",
      "S3a_J2_stream_3\n",
      "S3a_L_stream_0\n",
      "S3a_L_stream_1\n",
      "S3a_L_stream_2\n",
      "S3a_L_stream_3\n",
      "S3a_R_stream_0\n",
      "S3a_R_stream_1\n",
      "S3a_R_stream_2\n",
      "S3a_R_stream_3\n",
      "S3a_W_stream_0\n",
      "S3a_W_stream_1\n",
      "S3a_W_stream_2\n",
      "S3a_W_stream_3\n",
      "S4a_E_stream_0\n",
      "S4a_E_stream_1\n",
      "S4a_E_stream_2\n",
      "S4a_E_stream_3\n",
      "S4a_J1_stream_0\n",
      "S4a_J1_stream_1\n",
      "S4a_J1_stream_2\n",
      "S4a_J1_stream_3\n",
      "S4a_J2_stream_0\n",
      "S4a_J2_stream_1\n",
      "S4a_J2_stream_2\n",
      "S4a_J2_stream_3\n",
      "S4a_L_stream_0\n",
      "S4a_L_stream_1\n",
      "S4a_L_stream_2\n",
      "S4a_L_stream_3\n",
      "S4a_R_stream_0\n",
      "S4a_R_stream_1\n",
      "S4a_R_stream_2\n",
      "S4a_R_stream_3\n",
      "S4a_W_stream_0\n",
      "S4a_W_stream_1\n",
      "S4a_W_stream_2\n",
      "S4a_W_stream_3\n",
      "S4b_E_stream_0\n",
      "S4b_E_stream_1\n",
      "S4b_E_stream_2\n",
      "S4b_E_stream_3\n",
      "S4b_J1_stream_0\n",
      "S4b_J1_stream_1\n",
      "S4b_J1_stream_2\n",
      "S4b_J1_stream_3\n",
      "S4b_J2_stream_0\n",
      "S4b_J2_stream_1\n",
      "S4b_J2_stream_2\n",
      "S4b_J2_stream_3\n",
      "S4b_L_stream_0\n",
      "S4b_L_stream_1\n",
      "S4b_L_stream_2\n",
      "S4b_L_stream_3\n",
      "S4b_R_stream_0\n",
      "S4b_R_stream_1\n",
      "S4b_R_stream_2\n",
      "S4b_R_stream_3\n",
      "S4b_W_stream_0\n",
      "S4b_W_stream_1\n",
      "S4b_W_stream_2\n",
      "S4b_W_stream_3\n",
      "S5a_E_stream_0\n",
      "S5a_E_stream_1\n",
      "S5a_E_stream_2\n",
      "S5a_E_stream_3\n",
      "S5a_J1_stream_0\n",
      "S5a_J1_stream_1\n",
      "S5a_J1_stream_2\n",
      "S5a_J1_stream_3\n",
      "S5a_J2_stream_0\n",
      "S5a_J2_stream_1\n",
      "S5a_J2_stream_2\n",
      "S5a_J2_stream_3\n",
      "S5a_LOS_stream_0\n",
      "S5a_LOS_stream_1\n",
      "S5a_LOS_stream_2\n",
      "S5a_LOS_stream_3\n",
      "S5a_L_stream_0\n",
      "S5a_L_stream_1\n",
      "S5a_L_stream_2\n",
      "S5a_L_stream_3\n",
      "S5a_R_stream_0\n",
      "S5a_R_stream_1\n",
      "S5a_R_stream_2\n",
      "S5a_R_stream_3\n",
      "S5a_W_stream_0\n",
      "S5a_W_stream_1\n",
      "S5a_W_stream_2\n",
      "S5a_W_stream_3\n",
      "S6a_E_stream_0\n",
      "S6a_E_stream_1\n",
      "S6a_E_stream_2\n",
      "S6a_E_stream_3\n",
      "S6a_J1_stream_0\n",
      "S6a_J1_stream_1\n",
      "S6a_J1_stream_2\n",
      "S6a_J1_stream_3\n",
      "S6a_J2_stream_0\n",
      "S6a_J2_stream_1\n",
      "S6a_J2_stream_2\n",
      "S6a_J2_stream_3\n",
      "S6a_L_stream_0\n",
      "S6a_L_stream_1\n",
      "S6a_L_stream_2\n",
      "S6a_L_stream_3\n",
      "S6a_R_stream_0\n",
      "S6a_R_stream_1\n",
      "S6a_R_stream_2\n",
      "S6a_R_stream_3\n",
      "S6a_W_stream_0\n",
      "S6a_W_stream_1\n",
      "S6a_W_stream_2\n",
      "S6a_W_stream_3\n",
      "S6b_E_stream_0\n",
      "S6b_E_stream_1\n",
      "S6b_E_stream_2\n",
      "S6b_E_stream_3\n",
      "S6b_J1_stream_0\n",
      "S6b_J1_stream_1\n",
      "S6b_J1_stream_2\n",
      "S6b_J1_stream_3\n",
      "S6b_J_0_stream_0\n",
      "S6b_J_0_stream_1\n",
      "S6b_J_0_stream_2\n",
      "S6b_J_0_stream_3\n",
      "S6b_L_stream_0\n",
      "S6b_L_stream_1\n",
      "S6b_L_stream_2\n",
      "S6b_L_stream_3\n",
      "S6b_R_stream_0\n",
      "S6b_R_stream_1\n",
      "S6b_R_stream_2\n",
      "S6b_R_stream_3\n",
      "S6b_W_stream_0\n",
      "S6b_W_stream_1\n",
      "S6b_W_stream_2\n",
      "S6b_W_stream_3\n",
      "S7a_E_stream_0\n",
      "S7a_E_stream_1\n",
      "S7a_E_stream_2\n",
      "S7a_E_stream_3\n",
      "S7a_J1_stream_0\n",
      "S7a_J1_stream_1\n",
      "S7a_J1_stream_2\n",
      "S7a_J1_stream_3\n",
      "S7a_J2_stream_0\n",
      "S7a_J2_stream_1\n",
      "S7a_J2_stream_2\n",
      "S7a_J2_stream_3\n",
      "S7a_J3_stream_0\n",
      "S7a_J3_stream_1\n",
      "S7a_J3_stream_2\n",
      "S7a_J3_stream_3\n",
      "S7a_L1_stream_0\n",
      "S7a_L1_stream_1\n",
      "S7a_L1_stream_2\n",
      "S7a_L1_stream_3\n",
      "S7a_L2_stream_0\n",
      "S7a_L2_stream_1\n",
      "S7a_L2_stream_2\n",
      "S7a_L2_stream_3\n",
      "S7a_R1_stream_0\n",
      "S7a_R1_stream_1\n",
      "S7a_R1_stream_2\n",
      "S7a_R1_stream_3\n",
      "S7a_W_stream_0\n",
      "S7a_W_stream_1\n",
      "S7a_W_stream_2\n",
      "S7a_W_stream_3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\n",
    "    f\"{run_from_utils} python CSI_doppler_create_dataset_test.py '{run_from_data}/doppler_traces/' S2a,S2b,S3a,S4a,S4b,S5a,S6a,S6b,S7a 31 1 340 30 E,L,W,R,J 4\"\n",
    ")\n",
    "\n",
    "# e.g., python CSI_doppler_create_dataset_test.py ./doppler_traces/ S2a,S2b,S3a,S4a,S4b,S5a,S6a,S6b,S7a 31 1 340 30 E,L,W,R,J 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\u001b[1mModel: \"csi_model\"\u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer         │ (\u001b[96mNone\u001b[0m, \u001b[32m340\u001b[0m, \u001b[32m100\u001b[0m,  │          \u001b[32m0\u001b[0m │ -                 │\n",
      "│ (\u001b[94mInputLayer\u001b[0m)        │ \u001b[32m1\u001b[0m)                │            │                   │\n",
      "├─────────────────────┼───────────────────┼��───────────┼───────────────────┤\n",
      "│ 1stconv3_1_res_a    │ (\u001b[96mNone\u001b[0m, \u001b[32m340\u001b[0m, \u001b[32m100\u001b[0m,  │          \u001b[32m6\u001b[0m │ input_layer[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n",
      "│ (\u001b[94mConv2D\u001b[0m)            │ \u001b[32m3\u001b[0m)                │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_1        │ (\u001b[96mNone\u001b[0m, \u001b[32m340\u001b[0m, \u001b[32m100\u001b[0m,  │          \u001b[32m0\u001b[0m │ 1stconv3_1_res_a… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │ \u001b[32m3\u001b[0m)                │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼─────────��─────────┤\n",
      "│ 1stconv3_2_res_a    │ (\u001b[96mNone\u001b[0m, \u001b[32m340\u001b[0m, \u001b[32m100\u001b[0m,  │         \u001b[32m78\u001b[0m │ activation_1[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "│ (\u001b[94mConv2D\u001b[0m)            │ \u001b[32m6\u001b[0m)                │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_2        │ (\u001b[96mNone\u001b[0m, \u001b[32m340\u001b[0m, \u001b[32m100\u001b[0m,  │          \u001b[32m0\u001b[0m │ 1stconv3_2_res_a… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │ \u001b[32m6\u001b[0m)                │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ 1stconv2_1_res_a    │ (\u001b[96mNone\u001b[0m, \u001b[32m170\u001b[0m, \u001b[32m50\u001b[0m,   │         \u001b[32m25\u001b[0m │ input_layer[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n",
      "│ (\u001b[94mConv2D\u001b[0m)            │ \u001b[32m5\u001b[0m)                │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ 1stconv3_3_res_a    │ (\u001b[96mNone\u001b[0m, \u001b[32m170\u001b[0m, \u001b[32m50\u001b[0m,   │        \u001b[32m873\u001b[0m │ activation_2[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "│ (\u001b[94mConv2D\u001b[0m)            │ \u001b[32m9\u001b[0m)                │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ max_pooling2d       │ (\u001b[96mNone\u001b[0m, \u001b[32m170\u001b[0m, \u001b[32m50\u001b[0m,   │          \u001b[32m0\u001b[0m │ input_layer[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n",
      "│ (\u001b[94mMaxPooling2D\u001b[0m)      │ \u001b[32m1\u001b[0m)                │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation          │ (\u001b[96mNone\u001b[0m, \u001b[32m170\u001b[0m, \u001b[32m50\u001b[0m,   │          \u001b[32m0\u001b[0m │ 1stconv2_1_res_a… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │ \u001b[32m5\u001b[0m)                │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_3        │ (\u001b[96mNone\u001b[0m, \u001b[32m170\u001b[0m, \u001b[32m50\u001b[0m,   │          \u001b[32m0\u001b[0m │ 1stconv3_3_res_a… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │ \u001b[32m9\u001b[0m)                │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ concatenate         │ (\u001b[96mNone\u001b[0m, \u001b[32m170\u001b[0m, \u001b[32m50\u001b[0m,   │          \u001b[32m0\u001b[0m │ max_pooling2d[\u001b[32m0\u001b[0m]… │\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │ \u001b[32m15\u001b[0m)               │            │ activation[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n",
      "│                     │                   │            │ activation_3[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ conv4 (\u001b[94mConv2D\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[32m170\u001b[0m, \u001b[32m50\u001b[0m,   │         \u001b[32m48\u001b[0m │ concatenate[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n",
      "│                     │ \u001b[32m3\u001b[0m)                │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_4        │ (\u001b[96mNone\u001b[0m, \u001b[32m170\u001b[0m, \u001b[32m50\u001b[0m,   │          \u001b[32m0\u001b[0m │ conv4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]       │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │ \u001b[32m3\u001b[0m)                │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ flatten (\u001b[94mFlatten\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m25500\u001b[0m)     │          \u001b[32m0\u001b[0m │ activation_4[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "���─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ dropout (\u001b[94mDropout\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m25500\u001b[0m)     │          \u001b[32m0\u001b[0m │ flatten[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ dense2 (\u001b[94mDense\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[32m5\u001b[0m)         │    \u001b[32m127,505\u001b[0m │ dropout[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n",
      "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
      "\u001b[1m Total params: \u001b[0m\u001b[32m128,535\u001b[0m (502.09 KB)\n",
      "\u001b[1m Trainable params: \u001b[0m\u001b[32m128,535\u001b[0m (502.09 KB)\n",
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 15:39:38.634828: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 1.4472 - sparse_categorical_accuracy: 0.2536"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 15:40:01.711992: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 102ms/step - loss: 1.4467 - sparse_categorical_accuracy: 0.2540 - val_loss: 1.1360 - val_sparse_categorical_accuracy: 0.6531\n",
      "Epoch 2/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 99ms/step - loss: 0.9941 - sparse_categorical_accuracy: 0.7419 - val_loss: 0.5121 - val_sparse_categorical_accuracy: 0.8205\n",
      "Epoch 3/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 97ms/step - loss: 0.4032 - sparse_categorical_accuracy: 0.8735 - val_loss: 0.3139 - val_sparse_categorical_accuracy: 0.8875\n",
      "Epoch 4/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 100ms/step - loss: 0.2513 - sparse_categorical_accuracy: 0.9304 - val_loss: 0.2158 - val_sparse_categorical_accuracy: 0.9138\n",
      "Epoch 5/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 98ms/step - loss: 0.1733 - sparse_categorical_accuracy: 0.9634 - val_loss: 0.1430 - val_sparse_categorical_accuracy: 0.9786\n",
      "Epoch 6/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 97ms/step - loss: 0.1152 - sparse_categorical_accuracy: 0.9867 - val_loss: 0.1039 - val_sparse_categorical_accuracy: 0.9857\n",
      "Epoch 7/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 96ms/step - loss: 0.0858 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.0715 - val_sparse_categorical_accuracy: 0.9857\n",
      "Epoch 8/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 96ms/step - loss: 0.0565 - sparse_categorical_accuracy: 0.9944 - val_loss: 0.0481 - val_sparse_categorical_accuracy: 0.9924\n",
      "Epoch 9/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 102ms/step - loss: 0.0401 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0358 - val_sparse_categorical_accuracy: 0.9942\n",
      "Epoch 10/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 101ms/step - loss: 0.0308 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0274 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 11/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 100ms/step - loss: 0.0248 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0238 - val_sparse_categorical_accuracy: 0.9955\n",
      "Epoch 12/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 100ms/step - loss: 0.0175 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0196 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 13/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 103ms/step - loss: 0.0146 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.0157 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 14/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 101ms/step - loss: 0.0110 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0112 - val_sparse_categorical_accuracy: 0.9991\n",
      "Epoch 15/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 105ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.0090 - val_sparse_categorical_accuracy: 0.9996\n",
      "Epoch 16/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 105ms/step - loss: 0.0069 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0083 - val_sparse_categorical_accuracy: 0.9996\n",
      "Epoch 17/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 100ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.0082 - val_sparse_categorical_accuracy: 0.9996\n",
      "Epoch 18/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 103ms/step - loss: 0.0051 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0064 - val_sparse_categorical_accuracy: 0.9996\n",
      "Epoch 19/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 104ms/step - loss: 0.0036 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0125 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 20/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 102ms/step - loss: 0.0046 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0043 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 106ms/step - loss: 0.0025 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0045 - val_sparse_categorical_accuracy: 0.9996\n",
      "Epoch 22/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 105ms/step - loss: 0.0021 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 101ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 100ms/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 100ms/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0180 - val_sparse_categorical_accuracy: 0.9924\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step\n",
      "\u001b[1m 1/70\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 27ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 15:49:16.477797: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 15:49:21.026311: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\n",
    "    f\"{run_from_utils} python CSI_network.py '{run_from_data}/doppler_traces/' S1a 100 340 1 32 4 single_ant E,L,W,R,J\"\n",
    ")\n",
    "\n",
    "# e.g., python CSI_network.py ./doppler_traces/ S1a 100 340 1 32 4 single_ant E,L,W,R,J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "removing single_ant_E,L,W,R,J_cache_complete.data-00000-of-00001\n",
      "removing single_ant_E,L,W,R,J_cache_complete.index\n",
      "2872 files read\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step\n",
      "accuracy 0.9394150417827298\n",
      "fscore [1.         1.         0.8993187  0.95384615 0.81028152]\n",
      "[[601   0   0   0   0]\n",
      " [  0 552   0   0   0]\n",
      " [  0   0 594  19   0]\n",
      " [  0   0   0 620   0]\n",
      " [  0   0 114  41 331]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 00:59:16.181558: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\n",
    "    f\"{run_from_utils} python CSI_network_test.py --dir '{run_from_data}/doppler_traces/' --subdirs S7a --feature_length 100 --sample_length 340 --channels 1 --batch_size 32 --num_tot 4 --name_base single_ant --activities E,L,W,R,J\"\n",
    ")\n",
    "\n",
    "# e.g., python CSI_network_test.py --dir ./doppler_traces/ --subdirs S7a --feature_length 100 --sample_length 340 --channels 1 --batch_size 32 --num_tot 4 --name_base single_ant --activities E,L,W,R,J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single antenna - average accuracy 0.717967, average precision 0.719880, average recall 0.715279, average fscore 0.715279\n",
      "fscores - empty 0.975268, sitting 0.949381, walking 0.559080, running 0.599182, jumping 0.475447\n",
      "average fscore 0.711672\n",
      "accuracies - empty 0.984193, sitting 0.989583, walking 0.614600, running 0.502419, jumping 0.485597\n",
      "\n",
      "-- FINAL DECISION --\n",
      "max-merge - average accuracy 0.939415, average precision 0.950150, average recall 0.930015, average fscore 0.932689\n",
      "fscores - empty 1.000000, sitting 1.000000, walking 0.899319, running 0.953846, jumping 0.810282\n",
      "accuracies - empty 1.000000, sitting 1.000000, walking 0.969005, running 1.000000, jumping 0.681070\n",
      "\n",
      "accuracies - one antenna 0.717967, two antennas 0.825441, three antennas 0.906250, four antennas 0.939415\n",
      "fscores - one antenna 0.671384, two antennas 0.805051, three antennas 0.899097, four antennas 0.932689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\n",
    "    f\"{run_from_utils} python CSI_network_metrics.py 'complete_different_E,L,W,R,J_S7a_band_80_subband_1' E,L,W,R,J\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/plots_utility.py:216: UserWarning: There are no gridspecs with layoutgrids. Possibly did not call parent GridSpec with the \"figure\" keyword\n",
      "  plt.savefig(name_fig)\n",
      "/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/plots_utility.py:216: UserWarning: There are no gridspecs with layoutgrids. Possibly did not call parent GridSpec with the \"figure\" keyword\n",
      "  plt.savefig(name_fig)\n",
      "/Users/mattiapiazza/Documents/University/Human Data Analytics/HDA_activity_recognition/activity_recognition/utils/plots_utility.py:216: UserWarning: There are no gridspecs with layoutgrids. Possibly did not call parent GridSpec with the \"figure\" keyword\n",
      "  plt.savefig(name_fig)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\n",
    "    f\"{run_from_utils} python CSI_network_metrics_plot.py 'complete_different_E,L,W,R,J_S7a_band_80_subband_1' E,L,W,R,J\"\n",
    ")\n",
    "\n",
    "# e.g., python CSI_network_metrics_plot.py complete_different_E,L,W,R,J_S7a_band_80_subband_1 E,L,W,R,J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'conf_matrix'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2366</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "       <span style=\"font-weight: bold\">[</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2185</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"font-weight: bold\">]</span>,\n",
       "       <span style=\"font-weight: bold\">[</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1507</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">332</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">613</span><span style=\"font-weight: bold\">]</span>,\n",
       "       <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">82</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">705</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1246</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">447</span><span style=\"font-weight: bold\">]</span>,\n",
       "       <span style=\"font-weight: bold\">[</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">727</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">944</span><span style=\"font-weight: bold\">]])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'accuracy_single'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.717966573816156</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'precision_single'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.96650327</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91231733</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.51275944</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7421084</span> , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.46571288</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'recall_single'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98419301</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98958333</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.61460033</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.50241935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.48559671</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'fscore_single'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97526793</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94938084</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.55907995</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5991825</span> , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.47544699</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'conf_matrix_max_merge'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">601</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "       <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">552</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "       <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">594</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "       <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">620</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "       <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">114</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">331</span><span style=\"font-weight: bold\">]])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'accuracy_max_merge'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9394150417827298</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'precision_max_merge'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.        , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.        , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.83898305</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91176471</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.        <span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'recall_max_merge'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.        , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.        , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.96900489</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.        , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.68106996</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'fscore_max_merge'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.        , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.        , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8993187</span> , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95384615</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.81028152</span><span style=\"font-weight: bold\">])</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'conf_matrix'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2366\u001b[0m,   \u001b[1;36m38\u001b[0m,    \u001b[1;36m0\u001b[0m,    \u001b[1;36m0\u001b[0m,    \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m   \u001b[1;36m0\u001b[0m, \u001b[1;36m2185\u001b[0m,    \u001b[1;36m0\u001b[0m,    \u001b[1;36m0\u001b[0m,   \u001b[1;36m23\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m   \u001b[1;36m0\u001b[0m,    \u001b[1;36m0\u001b[0m, \u001b[1;36m1507\u001b[0m,  \u001b[1;36m332\u001b[0m,  \u001b[1;36m613\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m  \u001b[1;36m82\u001b[0m,    \u001b[1;36m0\u001b[0m,  \u001b[1;36m705\u001b[0m, \u001b[1;36m1246\u001b[0m,  \u001b[1;36m447\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m   \u001b[1;36m0\u001b[0m,  \u001b[1;36m172\u001b[0m,  \u001b[1;36m727\u001b[0m,  \u001b[1;36m101\u001b[0m,  \u001b[1;36m944\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'accuracy_single'\u001b[0m: \u001b[1;36m0.717966573816156\u001b[0m,\n",
       "    \u001b[32m'precision_single'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.96650327\u001b[0m, \u001b[1;36m0.91231733\u001b[0m, \u001b[1;36m0.51275944\u001b[0m, \u001b[1;36m0.7421084\u001b[0m , \u001b[1;36m0.46571288\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'recall_single'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.98419301\u001b[0m, \u001b[1;36m0.98958333\u001b[0m, \u001b[1;36m0.61460033\u001b[0m, \u001b[1;36m0.50241935\u001b[0m, \u001b[1;36m0.48559671\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'fscore_single'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.97526793\u001b[0m, \u001b[1;36m0.94938084\u001b[0m, \u001b[1;36m0.55907995\u001b[0m, \u001b[1;36m0.5991825\u001b[0m , \u001b[1;36m0.47544699\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'conf_matrix_max_merge'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m601\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m  \u001b[1;36m0\u001b[0m, \u001b[1;36m552\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m  \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m, \u001b[1;36m594\u001b[0m,  \u001b[1;36m19\u001b[0m,   \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m  \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m, \u001b[1;36m620\u001b[0m,   \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m  \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m, \u001b[1;36m114\u001b[0m,  \u001b[1;36m41\u001b[0m, \u001b[1;36m331\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'accuracy_max_merge'\u001b[0m: \u001b[1;36m0.9394150417827298\u001b[0m,\n",
       "    \u001b[32m'precision_max_merge'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m.        , \u001b[1;36m1\u001b[0m.        , \u001b[1;36m0.83898305\u001b[0m, \u001b[1;36m0.91176471\u001b[0m, \u001b[1;36m1\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'recall_max_merge'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m.        , \u001b[1;36m1\u001b[0m.        , \u001b[1;36m0.96900489\u001b[0m, \u001b[1;36m1\u001b[0m.        , \u001b[1;36m0.68106996\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'fscore_max_merge'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m.        , \u001b[1;36m1\u001b[0m.        , \u001b[1;36m0.8993187\u001b[0m , \u001b[1;36m0.95384615\u001b[0m, \u001b[1;36m0.81028152\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "p = Path(\n",
    "    \"activity_recognition/utils/outputs/complete_different_E,L,W,R,J_S7a_band_80_subband_1.txt\"\n",
    ")\n",
    "\n",
    "with open(p, \"rb\") as fp:\n",
    "    print(pickle.load(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
